import tkinter as tk
from tkinter import scrolledtext
import threading
from transformers import pipeline
import queue

class AIContentGenerator:
    def __init__(self, root):
        self.root = root
        self.root.title("Local AI Content Generator")
        
        # Initialize queue for thread-safe communication
        self.queue = queue.Queue()
        
        # Initialize the AI model
        self.model = None
        self.model_loaded = False
        
        # Create GUI elements
        self.create_gui()
        
        # Start loading model in background
        self.load_model_thread = threading.Thread(target=self.load_model)
        self.load_model_thread.start()
        
        # Start queue processing
        self.process_queue()

    def create_gui(self):
        # Input frame
        input_frame = tk.Frame(self.root)
        input_frame.pack(padx=10, pady=5, fill=tk.X)
        
        tk.Label(input_frame, text="Prompt:").pack(side=tk.LEFT)
        self.prompt_entry = tk.Entry(input_frame)
        self.prompt_entry.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(5, 5))
        
        # Create generate button
        self.generate_button = tk.Button(
            input_frame, 
            text="Generate", 
            command=self.generate_content
        )
        self.generate_button.pack(side=tk.LEFT, padx=(5, 0))
        
        # Create status label
        self.status_label = tk.Label(
            self.root, 
            text="Loading model...", 
            fg="orange"
        )
        self.status_label.pack(pady=(0, 5))
        
        # Create output text area
        self.output_text = scrolledtext.ScrolledText(
            self.root, 
            height=20, 
            width=60, 
            wrap=tk.WORD
        )
        self.output_text.pack(padx=10, pady=(0, 10), fill=tk.BOTH, expand=True)

    def load_model(self):
        try:
            # Load a small model suitable for local running
            self.model = pipeline(
                "text-generation",
                model="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                device="cpu"  # Use CPU by default
            )
            self.queue.put(("status", "Model loaded successfully", "green"))
            self.model_loaded = True
        except Exception as e:
            self.queue.put(("status", f"Error loading model: {str(e)}", "red"))

    def generate_content(self):
        if not self.model_loaded:
            self.output_text.insert(tk.END, "Please wait for model to load...\n")
            return
            
        prompt = self.prompt_entry.get()
        if not prompt:
            self.output_text.insert(tk.END, "Please enter a prompt.\n")
            return
            
        # Disable button while generating
        self.generate_button.config(state=tk.DISABLED)
        self.queue.put(("status", "Generating content...", "orange"))
        
        # Start generation in separate thread
        threading.Thread(target=self.generate_in_background, args=(prompt,)).start()

    def generate_in_background(self, prompt):
        try:
            result = self.model(
                prompt,
                max_length=200,
                num_return_sequences=1,
                temperature=0.7
            )[0]['generated_text']
            
            self.queue.put(("output", result))
            self.queue.put(("status", "Ready", "green"))
        except Exception as e:
            self.queue.put(("output", f"Error generating content: {str(e)}"))
            self.queue.put(("status", "Error occurred", "red"))
        finally:
            self.queue.put(("enable_button",))

    def process_queue(self):
        try:
            while True:
                msg = self.queue.get_nowait()
                if msg[0] == "status":
                    self.status_label.config(text=msg[1], fg=msg[2])
                elif msg[0] == "output":
                    self.output_text.insert(tk.END, msg[1] + "\n\n")
                    self.output_text.see(tk.END)
                elif msg[0] == "enable_button":
                    self.generate_button.config(state=tk.NORMAL)
        except queue.Empty:
            pass
        finally:
            # Schedule next queue check
            self.root.after(100, self.process_queue)

if __name__ == "__main__":
    root = tk.Window()
    app = AIContentGenerator(root)
    root.mainloop()
